{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: Detection of aggressive tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training dataset: 12776 tweets<br/> \n",
    "Validation dataset: 3194 tweets<br/> \n",
    "Test dataset: 3993 tweets<br/>\n",
    "Tweets are labeled (by human) as:\n",
    "* 1 (Cyber-Aggressive)\n",
    "* 0 (Non Cyber-Aggressive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "from keras.models import load_model\n",
    "from keras.utils import print_summary\n",
    "\n",
    "from mytextpreprocessing import TextPreprocessor\n",
    "from mytextpreprocessing import FrequencyExtractor\n",
    "from mytextpreprocessing import DocumentsSimilarity\n",
    "from mytextpreprocessing import WordToIndexTransformer\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './Data'\n",
    "data_train = pd.read_json(os.path.join(data_path, 'train.json'))\n",
    "data_valid = pd.read_json(os.path.join(data_path, 'valid.json'))\n",
    "data_test = pd.read_json(os.path.join(data_path, 'test.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = data_train.content, data_train.label\n",
    "X_valid, y_valid = data_valid.content, data_valid.label\n",
    "X_test, y_test = data_test.content, data_test.label\n",
    "\n",
    "X_train_extended = np.r_[X_train, X_valid]\n",
    "y_train_extended = np.r_[y_train, y_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([7706, 5070]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([2460, 1533]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logisticregression2.p\n",
      "logisticregression18.p\n",
      "rbfsvm2.p\n",
      "rbfsvm18.p\n",
      "baggingtree2.p\n",
      "baggingtree25.p\n",
      "xgb2.p\n",
      "xgb15.p\n",
      "xgb31.p\n"
     ]
    }
   ],
   "source": [
    "models_path = 'Models'\n",
    "file_names = ['logisticregression2.p', 'logisticregression18.p', \n",
    "              'rbfsvm2.p', 'rbfsvm18.p',\n",
    "              'baggingtree2.p', 'baggingtree25.p',\n",
    "              'xgb2.p', 'xgb15.p', 'xgb31.p']\n",
    "\n",
    "results = pd.DataFrame(columns=['train_accuracy', 'test_accuracy'])\n",
    "for file_name in file_names:\n",
    "    with open(os.path.join(models_path, file_name), 'rb') as file:\n",
    "        print(file_name)\n",
    "        loaded_model = pickle.load(file)\n",
    "        train_score = loaded_model.score(X_train_extended, y_train_extended)\n",
    "        test_score = loaded_model.score(X_test, y_test)\n",
    "        results.loc[file_name] = [train_score, test_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim.p\n"
     ]
    }
   ],
   "source": [
    "X_train_0 = DocumentsSimilarity(pos_label=0).get_docs_one_sent(X_train_extended, y_train_extended)\n",
    "X_train_1 = DocumentsSimilarity(pos_label=1).get_docs_one_sent(X_train_extended, y_train_extended)\n",
    "n_samples = 100\n",
    "X_train_n = np.r_[X_train_0[:n_samples], X_train_1[:n_samples]]\n",
    "y_train_n = np.array([0] * n_samples + [1] * n_samples)\n",
    "\n",
    "file_name = 'sim.p'\n",
    "with open(os.path.join(models_path, file_name), 'rb') as file:\n",
    "    print(file_name)\n",
    "    loaded_model = pickle.load(file)\n",
    "    y_train_pred = loaded_model.predict(X_train_n)\n",
    "    train_score = accuracy_score(y_true=y_train_n, y_pred=y_train_pred)\n",
    "    y_test_pred = loaded_model.predict(X_test.iloc[:n_samples])\n",
    "    test_score = accuracy_score(y_true=y_test.iloc[:n_samples], y_pred=y_test_pred)\n",
    "    results.loc[file_name] = [train_score, test_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(models_path, 'wordToIndex.p'), 'rb') as file:\n",
    "    wordToIndex = pickle.load(file)\n",
    "\n",
    "X_rnn_train = wordToIndex.transform(X_train)\n",
    "X_rnn_test = wordToIndex.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi20rnn.h5\n",
      "12776/12776 [==============================] - 15s 1ms/step\n",
      "3993/3993 [==============================] - 4s 1ms/step\n",
      "bi30rnn.h5\n",
      "12776/12776 [==============================] - 21s 2ms/step\n",
      "3993/3993 [==============================] - 5s 1ms/step\n",
      "bi30bi10rnn.h5\n",
      "12776/12776 [==============================] - 38s 3ms/step\n",
      "3993/3993 [==============================] - 11s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "file_names = ['bi20rnn.h5', 'bi30rnn.h5', 'bi30bi10rnn.h5']\n",
    "\n",
    "for file_name in file_names:\n",
    "    print(file_name)\n",
    "    loaded_model = load_model(os.path.join(models_path, file_name))\n",
    "    train_score = loaded_model.evaluate(X_rnn_train, y_train)[1]\n",
    "    test_score = loaded_model.evaluate(X_rnn_test, y_test)[1]\n",
    "    results.loc[file_name] = [train_score, test_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logisticregression2.p</th>\n",
       "      <td>0.976</td>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logisticregression18.p</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbfsvm2.p</th>\n",
       "      <td>0.997</td>\n",
       "      <td>0.965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbfsvm18.p</th>\n",
       "      <td>0.997</td>\n",
       "      <td>0.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baggingtree2.p</th>\n",
       "      <td>0.742</td>\n",
       "      <td>0.701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baggingtree25.p</th>\n",
       "      <td>0.751</td>\n",
       "      <td>0.716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb2.p</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb15.p</th>\n",
       "      <td>0.983</td>\n",
       "      <td>0.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb31.p</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sim.p</th>\n",
       "      <td>0.985</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi30rnn.h5</th>\n",
       "      <td>0.985</td>\n",
       "      <td>0.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi20rnn.h5</th>\n",
       "      <td>0.981</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi30bi10rnn.h5</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        train_accuracy  test_accuracy\n",
       "logisticregression2.p            0.976          0.890\n",
       "logisticregression18.p           0.798          0.744\n",
       "rbfsvm2.p                        0.997          0.965\n",
       "rbfsvm18.p                       0.997          0.962\n",
       "baggingtree2.p                   0.742          0.701\n",
       "baggingtree25.p                  0.751          0.716\n",
       "xgb2.p                           0.988          0.916\n",
       "xgb15.p                          0.983          0.914\n",
       "xgb31.p                          0.990          0.916\n",
       "sim.p                            0.985          0.760\n",
       "bi30rnn.h5                       0.985          0.871\n",
       "bi20rnn.h5                       0.981          0.872\n",
       "bi30bi10rnn.h5                   0.973          0.874"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(results, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
